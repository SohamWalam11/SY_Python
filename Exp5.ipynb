{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65949d1b-2aeb-40d5-9c2c-df848154eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a string:  Hello World! Welcome to the world of Data Science\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'hello', 'of', 'science', 'the', 'to', 'welcome', 'world']\n"
     ]
    }
   ],
   "source": [
    "# Exp5_1\n",
    "import re\n",
    "s = input(\"Enter a string: \")\n",
    "print(sorted(list(set(re.findall(r\"\\w+\",s.lower())))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b32c94-b744-4651-8222-46be126029fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Barack Obama': 1, 'Hawaii': 1, 'Google': 1}\n"
     ]
    }
   ],
   "source": [
    "# Exp5_2\n",
    "import re \n",
    "s = \"Barack Obama was born in Hawaii. Google is a major techcompany.\"\n",
    "pattern = r\"[A-Z][a-z]+\\s[A-Z][a-z]+|[A-Z][a-z]+\"\n",
    "res = re.findall(pattern,s)\n",
    "fre={}\n",
    "for ele in res:\n",
    "    fre[ele]=fre.get(ele,0)+1\n",
    "print(fre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "10f2210f-e7d3-4250-b9c2-a92e0638a311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2024-12-31', '2024-01-15']\n"
     ]
    }
   ],
   "source": [
    "# Exp5_3\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_and_normalize_dates_regex(text):\n",
    "    dates = []\n",
    "    patterns = [\n",
    "        r'\\b(\\d{1,2})[/-](\\d{1,2})[/-](\\d{2,4})\\b',  # MM/DD/YYYY or MM-DD-YYYY or DD/MM/YYYY or DD-MM-YYYY\n",
    "        r'\\b(\\d{4})[/-](\\d{1,2})[/-](\\d{1,2})\\b',  # YYYY/MM/DD or YYYY-MM-DD\n",
    "        r'\\b(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (\\d{1,2}), (\\d{4})\\b',  # Month Day, Year\n",
    "        r'\\b(\\d{1,2}) (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (\\d{4})\\b'  # Day Month Year\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        for match in matches:\n",
    "            if len(match[2]) == 2:  # Handle 2-digit year\n",
    "                year = '20' + match[2]\n",
    "            else:\n",
    "                year = match[2]\n",
    "            if pattern == patterns[0]:  # MM/DD/YYYY or MM-DD-YYYY or DD/MM/YYYY or DD-MM-YYYY\n",
    "                month, day, year = match\n",
    "            elif pattern == patterns[1]:  # YYYY/MM/DD or YYYY-MM-DD\n",
    "                year, month, day = match\n",
    "            else:  # Month Day, Year or Day Month Year\n",
    "                month_name, day, year = match\n",
    "                month = {\n",
    "                    'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04', 'May': '05', 'Jun': '06',\n",
    "                    'Jul': '07', 'Aug': '08', 'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
    "                }[month_name]\n",
    "            date = datetime(int(year), int(month), int(day))\n",
    "            dates.append(date.strftime(\"%Y-%m-%d\"))\n",
    "    return dates\n",
    "\n",
    "text = \"The event is scheduled for 12/31/2024 and the deadline is 01-15-2024.\"\n",
    "dates = extract_and_normalize_dates_regex(text)\n",
    "print(dates)  # Output: ['2022-02-15', '2023-02-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd219033-edaa-4422-9c36-2cfc87f7c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'John Doe; age: 30; profession: Data Scientist'}\n",
      "{'name': 'John Doe; age: 30; profession: Data Scientist'}\n",
      "{'name': 'John Doe; age: 30; profession: Data Scientist'}\n"
     ]
    }
   ],
   "source": [
    "# Exp5_4\n",
    "import re\n",
    "\n",
    "def extract_key_value_pairs(text):\n",
    "    \n",
    "    pattern_1 = r'(\\w+)\\s*:\\s*(.*)' \n",
    "    pattern_2 = r'(\\w+)\\s*:\\s*(.*)' \n",
    "    pattern_3 = r'(\\w+)\\s*:\\s*(.*)'\n",
    "    matches_1 = re.findall(pattern_1, text)\n",
    "    matches_2 = re.findall(pattern_2, text)\n",
    "    matches_3 = re.findall(pattern_3, text)\n",
    "    kv_dict1 = {}\n",
    "    kv_dict2 = {}\n",
    "    kv_dict3 = {}\n",
    "    for match in matches_1:\n",
    "        key, value = match\n",
    "        kv_dict1[key] = value.strip()  # Remove leading/trailing whitespace from value\n",
    "    return kv_dict\n",
    "\n",
    "    for match in matches_2:\n",
    "        key, value = match\n",
    "        kv_dict2[key] = value.strip()  # Remove leading/trailing whitespace from value\n",
    "    return kv_dict\n",
    "\n",
    "    for match in matches_3:\n",
    "        key, value = match\n",
    "        kv_dict3[key] = value.strip()  # Remove leading/trailing whitespace from value\n",
    "    return kv_dict\n",
    "\n",
    "text = \"name: John Doe; age: 30; profession: Data Scientist\"\n",
    "kv_dict1 = extract_key_value_pairs(text)\n",
    "kv_dict2 = extract_key_value_pairs(text)\n",
    "kv_dict3 = extract_key_value_pairs(text)\n",
    "print(kv_dict1)  \n",
    "print(kv_dict2) \n",
    "print(kv_dict3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c537ff-f859-4fb4-ae2f-d8080a28d644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(123) 456-7890', '(987) 654-3210']\n"
     ]
    }
   ],
   "source": [
    "# Exp5_5\n",
    "import re\n",
    "\n",
    "def extract_and_format_phone_numbers(text):\n",
    "    # Regular expression pattern to match phone numbers\n",
    "    pattern = r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b|\\b\\(\\d{3}\\)[\\s.-]?\\d{3}[-.]?\\d{4}\\b|\\b\\d{3}[-.]?\\d{4}\\b'\n",
    "\n",
    "    # Find all phone numbers in the text\n",
    "    phone_numbers = re.findall(pattern, text)\n",
    "\n",
    "    # Format the phone numbers\n",
    "    formatted_phone_numbers = []\n",
    "    for phone_number in phone_numbers:\n",
    "        # Remove non-digit characters\n",
    "        digits = re.sub(r'\\D', '', phone_number)\n",
    "        \n",
    "        # Format the phone number\n",
    "        if len(digits) == 10:\n",
    "            formatted_phone_number = f\"({digits[:3]}) {digits[3:6]}-{digits[6:]}\"\n",
    "            formatted_phone_numbers.append(formatted_phone_number)\n",
    "        elif len(digits) == 7:\n",
    "            formatted_phone_number = f\"{digits[:3]}-{digits[3:]}\"\n",
    "            formatted_phone_numbers.append(formatted_phone_number)\n",
    "\n",
    "    return formatted_phone_numbers\n",
    "\n",
    "# Example usage\n",
    "text = \"Contact me at 1234567890 or 987-654-3210 .\"\n",
    "print(extract_and_format_phone_numbers(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbf95785-e0b8-4c4d-80df-965b41050d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1234.0, 789.0]\n"
     ]
    }
   ],
   "source": [
    "# Exp5_6\n",
    "import re\n",
    "\n",
    "def extract_currency_amounts(text):\n",
    "    patterns = [r'\\$(\\d{1,3}(?:,\\d{3})*)(?:\\.\\d+)?']\n",
    "    amounts = []\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        for match in matches:\n",
    "            amount = match.replace(',', '').replace('.', '')  # Remove commas and dots\n",
    "            amounts.append(float(amount))  # Convert to float\n",
    "    return amounts\n",
    "\n",
    "text = \"The price is $1,234.56 and $789.00 for the additionalities.\"\n",
    "amounts = extract_currency_amounts(text)\n",
    "print(amounts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9887daa9-3902-4f84-b3f2-e8e520725bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email address is:  ['Clearance@gmail.com']\n"
     ]
    }
   ],
   "source": [
    "    #Exp5_7\n",
    "    import re\n",
    "    a = 'Please contact us at Clearance@gmail.com or sales@yahoo.in'\n",
    "    patt = r\"[a-zA-Z0-9._%+-]+@gmail+.[a-zA-Z]{2,3}\"\n",
    "    find = re.findall(patt,a)\n",
    "    print(\"Email address is: \",find)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f0458ee-2e78-42da-a09a-68736947429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['978-3-16-148410-0', '978-0-306-40615-7']\n"
     ]
    }
   ],
   "source": [
    "# Exp5_8\n",
    "import re\n",
    "\n",
    "def extract(s):\n",
    "    isbn = re.findall(r\"[0-9]{3}\\-[0-9]{1}\\-[0-9]{2,3}\\-[0-9]{5,6}\\-[0-9]{1}\",s)\n",
    "    print(isbn)\n",
    "extract('The books have ISBN numbers like 978-3-16-148410-0 and 978-0-306-40615-7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5578044-614e-47f2-86a4-3eaa21c394ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World ! This is a link.\n"
     ]
    }
   ],
   "source": [
    "# Exp5_10\n",
    "import re\n",
    "from html import unescape\n",
    "from unicodedata import normalize\n",
    "\n",
    "def clean_and_preprocess_text(text): \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Unescape HTML entities\n",
    "    text = unescape(text)\n",
    "    \n",
    "    # Normalize Unicode characters (e.g., convert accented characters to their plain text equivalents)\n",
    "    text = normalize('NFKD', text)\n",
    "    \n",
    "    # Remove unnecessary white space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "text = \"Hello <b> World </b> ! This is a <a href='http://example.com'>link</a>.\"\n",
    "clean_text = clean_and_preprocess_text(text)\n",
    "print(clean_text)  # Output: \"This is a test with HTML tags, unnecessary white space, and special characters like and, ', and -.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0cd6c6c-1e71-44ad-b83e-cb1d1e4912f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted list for numbers is:  [2, 12, 25]\n"
     ]
    }
   ],
   "source": [
    "# Exp5_11\n",
    "import re\n",
    "s = \"The quantties are 12 apples, 2 oranges, 25 bananas.\"\n",
    "pattern = r'\\d+'\n",
    "find_1 = re.findall(pattern,s)\n",
    "sorted = list(map(int,find_1))\n",
    "sorted.sort()\n",
    "print(\"Sorted list for numbers is: \",sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfef0c82-687f-4cef-81df-03b28ac84457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtags': ['#DataScience', '#AI'], 'mentions': ['@JohnDoe'], 'urls': ['http://linked.in!']}\n"
     ]
    }
   ],
   "source": [
    "# Exp5_12\n",
    "import re\n",
    "\n",
    "def extract_social_media_entities(text):\n",
    "    entities = {'hashtags': [], 'mentions': [], 'urls': []}\n",
    "\n",
    "    # Extract hashtags\n",
    "    hashtag_pattern = r'#(\\w+)'\n",
    "    hashtags = re.findall(hashtag_pattern, text)\n",
    "    entities['hashtags'] = [f'#{hashtag}' for hashtag in hashtags]\n",
    "\n",
    "    # Extract mentions\n",
    "    mention_pattern = r'@(\\w+)'\n",
    "    mentions = re.findall(mention_pattern, text)\n",
    "    entities['mentions'] = [f'@{mention}' for mention in mentions]\n",
    "\n",
    "    # Extract URLs\n",
    "    url_pattern = r'https?://\\S+'\n",
    "    urls = re.findall(url_pattern, text)\n",
    "    entities['urls'] = urls\n",
    "\n",
    "    return entities\n",
    "\n",
    "post = \"Check out #DataScience and @JohnDoe's post at http://linked.in! #AI\"\n",
    "entities = extract_social_media_entities(post)\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55beaba1-fad2-44fd-9ea7-ed3dfc8e699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://example.com', 'https://secure-site.org', 'ftp://files.example']\n"
     ]
    }
   ],
   "source": [
    "# Exp5_9\n",
    "def extract(s):\n",
    " URLs = re.findall(r'[a-z]+[\\:]//[a-z-]+\\.[a-z]{2,}',s)\n",
    " print(URLs)\n",
    "extract('Visit our sites at http://example.com, https://secure-site.org, and ftp://files.example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac35395-0c62-44e4-9bbb-654891b7e928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
